{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Who Watches The Watchmen? Finding Spyplanes with Autoencoder Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the weirder datasets on Kaggle is the 'spyplanes' dataset. It consists of a bunch of flight data from 2015 and was originally used as part of a Buzzfeed News article where the author reckoned he could detect spyplanes apart from other aircraft using machine learning. His analysis worked by training a model on flight data for known FBI and US Security Services aircraft and then looking for other aircraft with similar behaviour.\n",
    "\n",
    "I think there is another approach to this problem.\n",
    "\n",
    "Surveillance-aircraft are, by definition, supposed to be difficult to identify. By comparing aircraft behaviour with that of known government aircraft, we risk missing many other planes which may behave drastically differently to those we manually identified. Rather than training a model on a known dataset (aka supervised learning), I decided it is more appropriate to scour the whole dataset of flight data for unusual behaviour (aka unsupervised learning). In other words, I'm going to look for aircraft which look 'weird'...otherwise known as outliers. To do this I'm going to use an autoencoder neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Full details of the dataset used are available at https://www.kaggle.com/jboysen/spy-plane-finder\n",
    "    \n",
    "It consists of modified flight data from 2015. As this project was more about finding an excuse to use an autoencoder, I chose a pretty convenient dataset which has already been engineered for features. Were I using raw flight data, I'd probably have performed the feature engineering differently, but that's not interesting now.\n",
    "\n",
    "Each entry includes an aircraft with a number of distance/time based metrics, to give an idea of the typical flight pattern. Also included is the aircraft type and transponder info and number of observations/flights seen over the period.\n",
    "\n",
    "The original author also included a small directory of aircraft which he believed were spy aircraft (as they were operated by the FBI or US Defence Department) and ones which he believed were not. In total he identified 97 probably spy aircraft and 500 non-spy aircraft. He used this 'known' dataset to train up his model. I am going to used it for model validation, but not in the normal sense. Remember, we don not know that all of the 97 aircraft are actually spyplanesand any of the 500 ones could be too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than training the model on a dataset and then testing it with known results, a kind of hybrid approach was used. A model was trained on a subset of the main dataset and then tested on the table of known aircraft. Since we do not know how many of the labels on the 'known' aircraft are correct, the performance was only really an estimate. The model was then applied to the rest of the main dataset to give candidate spyplanes. Normally we'd just run a model on the raw dataset and let it tell us which entries were the outliers, but in this case we have the luxury of some 'sort of' labelled data.\n",
    "\n",
    "First the necessary libraries are installed and the main dataset imported. A second table called 'labelled_data' is created. This contains the 'known' spyplanes and non-spyplanes and will be used to test the model. These aircraft are removed from the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#import dataset\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\Alex\\\\Documents\\\\datasets\\\\spy-plane-finder\\\\planes_features.csv\")\n",
    "\n",
    "#convert type column to integer (there are probably better approaches to use here)\n",
    "df['type']=df['type'].astype('category').cat.codes\n",
    "\n",
    "#import labelled aircraft\n",
    "test_ident = pd.read_csv(\"C:\\\\Users\\\\Alex\\\\Documents\\\\datasets\\\\spy-plane-finder\\\\train.csv\")\n",
    "\n",
    "#use the labelled data as a train/test set (note the different context of testing to normal for this model)\n",
    "labelled_data=df[df['adshex'].isin(test_ident['adshex'])]\n",
    "labelled_data=pd.merge(labelled_data,test_ident,on=['adshex','adshex'])\n",
    "labelled_data['type']=labelled_data['type'].astype('category').cat.codes\n",
    "labelled_data=labelled_data.drop(['adshex'],axis=1)\n",
    "\n",
    "df=df[~df['adshex'].isin(test_ident['adshex'])]\n",
    "df_adshex=df['adshex']\n",
    "df=df.drop(['adshex'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10% of the aircraft from the main dataset are then removed and used to build a training set. Note, the data was scaled between 0-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use 10% of the input data as a training set\n",
    "df,train_set=train_test_split(df,test_size=0.1,random_state=57)\n",
    "\n",
    "#also consider adding some of the actual data to the train/test set to improve the size\n",
    "test_set = labelled_data\n",
    "\n",
    "#save test set labels for later\n",
    "test_set_labels=test_set['class']\n",
    "#get number of positive classes in test set\n",
    "test_set_positives=len(test_set[test_set['class']=='surveil'])\n",
    "test_set = test_set.drop(['class'], axis=1)\n",
    "\n",
    "#convert to array and normalise\n",
    "train_set = preprocessing.MinMaxScaler().fit_transform(train_set.values)\n",
    "test_set = preprocessing.MinMaxScaler().fit_transform(test_set.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying A Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim was to find an algorithm which would identify outliers in the data. For this dataset, aircraft which behave oddly may well be surveillance aircraft. I used an autoencoder neural network to do this, here's how they work:\n",
    "\n",
    "INSERT DESCRIPTION HERE\n",
    "\n",
    "To do this with Keras/Tensorflow we first define the layers of the network. The input and output layers must be the same size as the data, with a node for each attribute. The intermediate layers wre half the size, to allow the network to compress the records as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define layers\n",
    "input_dim = test_set.shape[1]\n",
    "encoding_dim = int(input_dim/2)\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the model was run and the best performing model saved. Note, all the parameters like the optimiser and the loss function. These can be changes along with the number and size of the layers. This process is called hyperparameter tuning and we seek to find the best combination of hyperparameters to obtain the best results. For this excercise, some random paramaters were tried and the best selection chosen. Normally I'd tune the parameters far more extensivley but since this is just a demo I didn't want to get too bogged down with this part.\n",
    "\n",
    "Note, the model was only run on the 10% of aircraft which were used as the training set. Ideally I'd train it only on aircraft which were known not to be spyplanes. This would make it optimised for reconstructing 'normal' aircraft patterns only and unusual aircraft not seen in the training set would be reconstructed with a high degree of error. I figured very few of the training set aircraft would br spyplanes so this is probably not a huge issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nb_epoch = 100\n",
    "batch_size = 50\n",
    "autoencoder.compile(optimizer='Adamax', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "history = autoencoder.fit(train_set,train_set,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_set,test_set),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, tensorboard]).history\n",
    "\n",
    "autoencoder=load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to test the model on the dataset of 'known' aircraft. Remember, I am not convinced that all of those labelled 'spyplanes' are indeed spyplanes. Similarly, many of the aircraft labelled 'normal' could well be spylplanes. I was therfore not expecting great performance. To classify aircraft, I ensured the model only labelled the top 97 anomalous entries as spyplanes, because that is how many were labelled as such in the original 'known' aircraft dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict on testing set\n",
    "predictions=autoencoder.predict(test_set)\n",
    "rmse = pow(np.mean(np.power(test_set - predictions, 2), axis=1),0.5)\n",
    "error_table = pd.DataFrame({'reconstruction_error': rmse,\n",
    "                        'actual_class': test_set_labels})\n",
    "#we know how many entries have a positive in the test set. Take this number and label the predictions with the highest rmse (ie the outliers) with the positiveclass prediction\n",
    "error_table['predicted_class'] = np.where(error_table['reconstruction_error'] >= min(error_table.nlargest(int(test_set_positives),'reconstruction_error', keep='first')['reconstruction_error']), 'surveil', 'other')\n",
    "\n",
    "#get confusion matrix\n",
    "print(confusion_matrix(error_table['actual_class'],error_table['predicted_class']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I initially ran the script, 31 of the 97 spyplanes were correctly identified. By tuning the parameters, I managed to improve this to 54, which gives the following confusion matrix:\n",
    "\n",
    "|              |   normal   |  spyplane     |\n",
    "|--------------|------------|---------------|\n",
    "|   normal     |    457     |       43      |\n",
    "|--------------|------------|---------------|\n",
    "|   spyplane   |     43     |      54       |\n",
    "\n",
    "At first glance this might look like a not-too-great result but I was actually pretty impressed how well it performed - it found 54 of the 97 aircraft which were known to be government operated. Let's remember that the algorithm is identifying unusual aircraft just by the fact they fly in an irregular pattern - it is not using any known data to correlate observed aircraft with known spyplanes.\n",
    "\n",
    "Let's also remember that some of the aircraft identified as spyplanes which were labelled as 'normal' may indeed be spyplanes. The test data relies on accurate labelling of aircraft which is impossible.\n",
    "\n",
    "Let's have a look at the reconstruction error for each of the aircraft in the test set. This is a measure of how much of an outlier each aircraft was - recall the top 97 outliers were taken to be spyplanes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot error\n",
    "groups=error_table.groupby('actual_class')\n",
    "fig,ax=plt.subplots()\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index,group.reconstruction_error,marker='o', ms=3.5, linestyle='',\n",
    "            label= name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
